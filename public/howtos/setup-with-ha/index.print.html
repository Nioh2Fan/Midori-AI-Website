<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.125.7">
    <meta name="generator" content="Relearn 5.25.0+tip">
    <meta name="robots" content="noindex, nofollow, noarchive, noimageindex">
    <meta name="description" content="Documentation for Midori-AI">
    <meta name="author" content="Luna Midori">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Home Assistant x LocalAI :: Midori-AI">
    <meta name="twitter:description" content="Home Assistant is an open-source home automation platform that allows users to control and monitor various smart devices in their homes. It supports a wide range of devices, including lights, thermostats, security systems, and more. The platform is designed to be user-friendly and customizable, enabling users to create automations and routines to make their homes more convenient and efficient. Home Assistant can be accessed through a web interface or a mobile app, and it can be installed on a variety of hardware platforms, such as Raspberry Pi or a dedicated server.">
    <meta property="og:title" content="Home Assistant x LocalAI :: Midori-AI">
    <meta property="og:description" content="Home Assistant is an open-source home automation platform that allows users to control and monitor various smart devices in their homes. It supports a wide range of devices, including lights, thermostats, security systems, and more. The platform is designed to be user-friendly and customizable, enabling users to create automations and routines to make their homes more convenient and efficient. Home Assistant can be accessed through a web interface or a mobile app, and it can be installed on a variety of hardware platforms, such as Raspberry Pi or a dedicated server.">
    <meta property="og:type" content="article">
    <meta property="og:url" content="http://localhost:1313/howtos/setup-with-ha/index.html">
    <meta property="article:section" content="LocalAI How-tos :: Midori-AI">
    <meta property="og:site_name" content="Midori-AI">
    <title>Home Assistant x LocalAI :: Midori-AI</title>
    <!-- https://github.com/filamentgroup/loadCSS/blob/master/README.md#how-to-use -->
    <link href="/css/fontawesome-all.min.css?1724261814" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/css/fontawesome-all.min.css?1724261814" rel="stylesheet"></noscript>
    <link href="/css/nucleus.css?1724261814" rel="stylesheet">
    <link href="/css/auto-complete.css?1724261814" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/css/auto-complete.css?1724261814" rel="stylesheet"></noscript>
    <link href="/css/perfect-scrollbar.min.css?1724261814" rel="stylesheet">
    <link href="/css/fonts.css?1724261814" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/css/fonts.css?1724261814" rel="stylesheet"></noscript>
    <link href="/css/theme.css?1724261814" rel="stylesheet">
    <link href="/css/theme-auto.css?1724261814" rel="stylesheet" id="R-variant-style">
    <link href="/css/chroma-auto.css?1724261814" rel="stylesheet" id="R-variant-chroma-style">
    <link href="/css/variant.css?1724261814" rel="stylesheet">
    <link href="/css/print.css?1724261814" rel="stylesheet" media="print">
    <link href="/css/format-print.css?1724261814" rel="stylesheet">
    <link href="/css/ie.css?1724261814" rel="stylesheet">
    <script src="/js/url.js?1724261814"></script>
    <script src="/js/variant.js?1724261814"></script>
    <script>
      // hack to let hugo tell us how to get to the root when using relativeURLs, it needs to be called *url= for it to do its magic:
      // https://github.com/gohugoio/hugo/blob/145b3fcce35fbac25c7033c91c1b7ae6d1179da8/transform/urlreplacers/absurlreplacer.go#L72
      window.index_js_url="/index.search.js";
      var root_url="/";
      var baseUri=root_url.replace(/\/$/, '');
      window.relearn = window.relearn || {};
      window.relearn.baseUriFull='http:\/\/localhost:1313/';
      // variant stuff
      window.relearn.themeVariantModifier='';
      window.variants && variants.init( [ 'auto', 'relearn-bright', 'relearn-light', 'relearn-dark', 'learn', 'neon', 'blue', 'green', 'red' ] );
      // translations
      window.T_Copy_to_clipboard = `Copy to clipboard`;
      window.T_Copied_to_clipboard = `Copied to clipboard!`;
      window.T_Copy_link_to_clipboard = `Copy link to clipboard`;
      window.T_Link_copied_to_clipboard = `Copied link to clipboard!`;
      window.T_Reset_view = `Reset view`;
      window.T_View_reset = `View reset!`;
      window.T_No_results_found = `No results found for "{0}"`;
      window.T_N_results_found = `{1} results found for "{0}"`;
    </script>
  </head>
  <body class="mobile-support print disableInlineCopyToClipboard" data-url="/howtos/setup-with-ha/index.html">
    <div id="R-body" class="default-animation">
      <div id="R-body-overlay"></div>
      <nav id="R-topbar">
        <div class="topbar-wrapper">
          <div class="topbar-sidebar-divider"></div>
          <div class="topbar-area topbar-area-start" data-area="start">
            <div class="topbar-button topbar-button-sidebar" data-content-empty="disable" data-width-s="show" data-width-m="hide" data-width-l="hide"><button class="topbar-control" onclick="toggleNav()" type="button" title="Menu (CTRL&#43;ALT&#43;n)"><i class="fa-fw fas fa-bars"></i></button>
            </div>
          </div>
          <ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype="http://schema.org/BreadcrumbList"><li
            itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement"><a itemprop="item" href="/howtos/index.html"><span itemprop="name">LocalAI How-tos</span></a><meta itemprop="position" content="1">&nbsp;->&nbsp;</li><li
            itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement"><span itemprop="name">Home Assistant x LocalAI</span><meta itemprop="position" content="2"></li>
          </ol>
          <div class="topbar-area topbar-area-end" data-area="end">
          </div>
        </div>
      </nav>
      <div id="R-main-overlay"></div>
      <main id="R-body-inner" class="highlightable default" tabindex="-1">
        <div class="flex-block-wrapper">
          <article class="default">
            <header class="headline">
            </header>
<h1 id="home-assistant-x-localai">Home Assistant x LocalAI</h1>

<p>Home Assistant is an open-source home automation platform that allows users to control and monitor various smart devices in their homes. It supports a wide range of devices, including lights, thermostats, security systems, and more. The platform is designed  to be user-friendly and customizable, enabling users to create automations and routines to make their homes more convenient and efficient. Home Assistant can be accessed through a web interface or a mobile app, and it can be installed on a variety of hardware platforms, such as Raspberry Pi or a dedicated server.</p>
<p>Currently, Home Assistant supports conversation-based agents and services. As of writing this, OpenAIs API is supported as a conversation agent; however, access to your homes devices and entities is possible through custom components. Local based services, such as LocalAI, are also available as a drop-in replacement for OpenAI services.</p>
<h2 id="there-are-multiple-custom-integrations-available">There are multiple custom integrations available:</h2>
<p>Please note that both of the projects are similar in term of visual interfaces, they seem to be derived from the official Home Assistant plugin: <a href="https://www.home-assistant.io/integrations/openai_conversation/" target="_blank">OpenAI Conversation</a> (to be confirmed)</p>
<ul>
<li>Home-LLM is a Home Assistant integration developed by Alex O&rsquo;Connell (<a href="https://github.com/acon96" target="_blank">acon96</a>) that allows for a completely local Large Language Model acting as a personal assistant. Using LocalAI as the backend is one of the supported platforms. The provided Large Language Models are specifically trained for home assistant and are therefore smaller in size.</li>
<li>Extended OpenAI Conversation uses OpenAI API’s feature of function calling to call service of Home Assistant. Is more generic and work with most of the Large Language Model.</li>
</ul>
<h1 id="home-llm">Home-LLM</h1>
<h2 id="installation-instructions--localai">Installation Instructions – LocalAI</h2>
<p>To install LocalAI, use our <a href="/subsystem/manager/index.html">Midori AI Subsystem Manager</a></p>
<h2 id="installation-instructions--home-llm-the-ha-plugin">Installation Instructions – Home LLM (The HA plugin)</h2>
<p>Please follow the installation instructions on <a href="https://github.com/acon96/home-llm?tab=readme-ov-file#installing-with-hacs" target="_blank">Home-LLM</a> repo to install HACS plug-in.</p>
<h2 id="setting-up-the-plugin-for-ha--localai">Setting up the plugin for HA &amp; LocalAI</h2>
<p>Before adding the Llama Conversation agent in Home Assistant, you must download a LLM in the LocalAI models directory. Although you may use any model you want, this specific integration uses a model that has been specifically fine-tuned to work with Home Assistant. Performance will vary widely with other models.</p>
<p>The models can be found on the Midori AI model repo, as a part of the LocalAI manager.</p>
<p>Use the <a href="/subsystem/manager/index.html">Midori AI Subsystem Manager</a> for a easy time installing models or follow <a href="/howtos/by_hand/easy-model/index.html">Seting up a Model</a></p>
<h2 id="setting-up-the-remote-backend">Setting up the &ldquo;remote&rdquo; backend:</h2>
<p>You will need the following settings in order to configure LocalAI backend:</p>
<ul>
<li>Hostname: the host of the machine where LocalAI is installed and hosted.</li>
<li>Port: The port you listed in your <code>docker-compose.yaml</code> (normally <code>8080</code>)</li>
<li>Name of the Model as exactly in the <code>model.yaml</code> file: This name must EXACTLY match the name as it appears in the file.</li>
</ul>
<p>The component will validate that the selected model is available for use and will ensure it is loaded remotely.</p>
<p>Once you have this information, proceed to “add Integration” in Home Assistant and search for “Llama Conversation” Here you will be greeted with a config flow to add the above information. Once the information is accepted, search your integrations for “Llama Conversation” and you can now view your settings including prompt, temperature, top K and other parameters. For LocalAI use, please make sure to select that ChatML prompt and to use &lsquo;Use chat completions endpoint&rsquo;.</p>
<h2 id="configuring-the-component-as-a-conversation-agent">Configuring the component as a Conversation Agent</h2>
<p>In order to utilize the conversation agent in HomeAssistant, you will need to configure it as a conversation agent. This can be done by following the the instructions <a href="https://github.com/acon96/home-llm?tab=readme-ov-file#configuring-the-component-as-a-conversation-agent" target="_blank">here</a>.</p>
<h2 id="changing-the-prompt">Changing the prompt</h2>
<p>Example on how to use the prompt can be seen <a href="https://github.com/acon96/home-llm?tab=readme-ov-file#model" target="_blank">here</a>.</p>
<h1 id="extended-openai-conversation">Extended OpenAI Conversation</h1>
<p>The project has been introduced <a href="https://community.home-assistant.io/t/custom-component-extended-openai-conversation-lets-control-entities-via-chatgpt/636500" target="_blank">here</a>, and the Documentation is available directly <a href="https://github.com/jekalmin/extended_openai_conversation" target="_blank">on the author github project</a></p>
<h1 id="setup-summary">Setup summary</h1>
<p>LocalAI must be working with an installed LLM.
You can directly ask the model if he is compatible with Home Assistant. To be confirmed: the model may work evene if it says he is not compatible. Mistral and Mixtral are compatible.
Then install the Home Assistant integration, and follow the documentation provided above.
High level Overview of the setup:</p>
<ul>
<li>add the repository in HACS.</li>
<li>install the integration.</li>
<li>fill the needed information. You must fill something in the API key (if you don&rsquo;t use api key just check the box &ldquo;ignore authentication&rdquo;), put the full url e.g. https://myLocalAIHostHere:8080/v1 (including /v1), Not sure: let the API version empty.</li>
<li>configure the Home Assistant <a href="https://www.home-assistant.io/voice_control/" target="_blank">Assist</a> using the new conversation agent.</li>
</ul>

<div class="box notices cstyle warning">
  <div class="box-label"><i class="fa-fw fas fa-exclamation-triangle"></i> Notice</div>
  <div class="box-content">

<p><strong>Important Note:</strong></p>
<p>Any devices you choose to expose to the model will be added to the context and may have their state changed by the model. Only expose devices that you are comfortable with the model modifying, even if the modification is not what you intended. The model may occasionally hallucinate and issue commands to the wrong device. Use at your own risk.</p>
</div>
</div>

            <footer class="footline">
            </footer>
          </article>

        </div>
      </main>
    </div>
    <script src="/js/clipboard.min.js?1724268900" defer></script>
    <script src="/js/perfect-scrollbar.min.js?1724268900" defer></script>
    <script src="/js/theme.js?1724268900" defer></script>
  </body>
</html>
