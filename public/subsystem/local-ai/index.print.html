<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.125.7">
    <meta name="generator" content="Relearn 5.25.0+tip">
    <meta name="robots" content="noindex, nofollow, noarchive, noimageindex">
    <meta name="description" content="Documentation for Midori-AI">
    <meta name="author" content="Luna Midori">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="LocalAI :: Midori-AI">
    <meta name="twitter:description" content="Documentation for Midori-AI">
    <meta property="og:title" content="LocalAI :: Midori-AI">
    <meta property="og:description" content="Documentation for Midori-AI">
    <meta property="og:type" content="website">
    <meta property="og:url" content="http://localhost:1313/subsystem/local-ai/index.html">
    <meta property="og:site_name" content="Midori-AI">
    <title>LocalAI :: Midori-AI</title>
    <!-- https://github.com/filamentgroup/loadCSS/blob/master/README.md#how-to-use -->
    <link href="/css/fontawesome-all.min.css?1722385083" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/css/fontawesome-all.min.css?1722385083" rel="stylesheet"></noscript>
    <link href="/css/nucleus.css?1722385083" rel="stylesheet">
    <link href="/css/auto-complete.css?1722385083" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/css/auto-complete.css?1722385083" rel="stylesheet"></noscript>
    <link href="/css/perfect-scrollbar.min.css?1722385083" rel="stylesheet">
    <link href="/css/fonts.css?1722385083" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/css/fonts.css?1722385083" rel="stylesheet"></noscript>
    <link href="/css/theme.css?1722385083" rel="stylesheet">
    <link href="/css/theme-auto.css?1722385083" rel="stylesheet" id="R-variant-style">
    <link href="/css/chroma-auto.css?1722385083" rel="stylesheet" id="R-variant-chroma-style">
    <link href="/css/variant.css?1722385083" rel="stylesheet">
    <link href="/css/print.css?1722385083" rel="stylesheet" media="print">
    <link href="/css/format-print.css?1722385083" rel="stylesheet">
    <link href="/css/ie.css?1722385083" rel="stylesheet">
    <script src="/js/url.js?1722385083"></script>
    <script src="/js/variant.js?1722385083"></script>
    <script>
      // hack to let hugo tell us how to get to the root when using relativeURLs, it needs to be called *url= for it to do its magic:
      // https://github.com/gohugoio/hugo/blob/145b3fcce35fbac25c7033c91c1b7ae6d1179da8/transform/urlreplacers/absurlreplacer.go#L72
      window.index_js_url="/index.search.js";
      var root_url="/";
      var baseUri=root_url.replace(/\/$/, '');
      window.relearn = window.relearn || {};
      window.relearn.baseUriFull='http:\/\/localhost:1313/';
      // variant stuff
      window.relearn.themeVariantModifier='';
      window.variants && variants.init( [ 'auto', 'relearn-bright', 'relearn-light', 'relearn-dark', 'learn', 'neon', 'blue', 'green', 'red' ] );
      // translations
      window.T_Copy_to_clipboard = `Copy to clipboard`;
      window.T_Copied_to_clipboard = `Copied to clipboard!`;
      window.T_Copy_link_to_clipboard = `Copy link to clipboard`;
      window.T_Link_copied_to_clipboard = `Copied link to clipboard!`;
      window.T_Reset_view = `Reset view`;
      window.T_View_reset = `View reset!`;
      window.T_No_results_found = `No results found for "{0}"`;
      window.T_N_results_found = `{1} results found for "{0}"`;
    </script>
  </head>
  <body class="mobile-support print disableInlineCopyToClipboard" data-url="/subsystem/local-ai/index.html">
    <div id="R-body" class="default-animation">
      <div id="R-body-overlay"></div>
      <nav id="R-topbar">
        <div class="topbar-wrapper">
          <div class="topbar-sidebar-divider"></div>
          <div class="topbar-area topbar-area-start" data-area="start">
            <div class="topbar-button topbar-button-sidebar" data-content-empty="disable" data-width-s="show" data-width-m="hide" data-width-l="hide"><button class="topbar-control" onclick="toggleNav()" type="button" title="Menu (CTRL&#43;ALT&#43;n)"><i class="fa-fw fas fa-bars"></i></button>
            </div>
          </div>
          <ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype="http://schema.org/BreadcrumbList"><li
            itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement"><a itemprop="item" href="/subsystem/index.html"><span itemprop="name">Midori AI Subsystem</span></a><meta itemprop="position" content="1">&nbsp;->&nbsp;</li><li
            itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement"><span itemprop="name">LocalAI</span><meta itemprop="position" content="2"></li>
          </ol>
          <div class="topbar-area topbar-area-end" data-area="end">
          </div>
        </div>
      </nav>
      <div id="R-main-overlay"></div>
      <main id="R-body-inner" class="highlightable default" tabindex="-1">
        <div class="flex-block-wrapper">
          <article class="default">
            <header class="headline">
            </header>
<h1 id="localai">LocalAI</h1>

<p><a href="#R-image-79d638f5c31bf5c4f3f88aecd6e4636c" class="lightbox-link"><img src="https://tea-cup.midori-ai.xyz/download/Midori_subsystem_x_localai.png" alt="Midori AI photo" class="figure-image noborder lightbox noshadow" style="height: auto; width: auto;" loading="lazy"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-79d638f5c31bf5c4f3f88aecd6e4636c"><img src="https://tea-cup.midori-ai.xyz/download/Midori_subsystem_x_localai.png" alt="Midori AI photo" class="lightbox-image noborder lightbox noshadow" loading="lazy"></a></p>
<p>Here is a link to <a href="https://github.com/mudler/LocalAI" target="_blank">LocalAI Github</a></p>
<h2 id="installing-localai-a-step-by-step-guide">Installing LocalAI: A Step-by-Step Guide</h2>
<p>This guide will walk you through the process of installing LocalAI on your system. Please follow the steps carefully for a successful installation.</p>
<h3 id="step-1-initiate-installation">Step 1: Initiate Installation</h3>
<ol>
<li>From the main menu, enter the option <code>2</code> to begin the installation process.</li>
<li>You will be prompted with a visual confirmation.</li>
</ol>
<h3 id="step-2-confirm-gpu-backend">Step 2: Confirm GPU Backend</h3>
<ol>
<li>Respond to the prompt with either <code>yes</code> or <code>no</code> to proceed with GPU support or CPU support only, respectively.</li>
</ol>
<h3 id="step-3-confirm-localai-installation">Step 3: Confirm LocalAI installation</h3>
<ol>
<li>Type <code>localai</code> into the menu and press Enter to start the LocalAI installation.</li>
</ol>
<h3 id="step-4-wait-for-setup-completion">Step 4: Wait for Setup Completion</h3>
<ol>
<li>LocalAI will now automatically configure itself. This process may take approximately 10 to 30 minutes.</li>
<li><strong>Important:</strong> Please do not restart your system or attempt to send requests to LocalAI during this setup phase.</li>
</ol>
<h3 id="step-5-access-localai">Step 5: Access LocalAI</h3>
<ol>
<li>Once the setup is complete, you can access LocalAI on port <code>38080</code>.</li>
</ol>

<div class="box notices cstyle info">
  <div class="box-label"><i class="fa-fw fas fa-info-circle"></i> Important Notes</div>
  <div class="box-content">

<ul>
<li>Remember to use your computer&rsquo;s IP address instead of <code>localhost</code> when accessing LocalAI. For example, you would use <code>192.168.10.10:38080/v1</code> or <code>192.168.1.3:38080/v1</code> depending on your network configuration.</li>
</ul>
</div>
</div>
<h3 id="support-and-assistance">Support and Assistance</h3>
<p>If you encounter any issues or require further assistance, please feel free to reach out through the following channels:</p>
<ul>
<li><strong>Midori AI Discord:</strong> <a href="https://discord.gg/xdgCx3VyHU" target="_blank">https://discord.gg/xdgCx3VyHU</a></li>
<li><strong>Midori AI Email:</strong> <a href="mailto:contact-us@midori-ai.xyz" target="_blank">Email Us</a></li>
<li><strong>LocalAI Discord:</strong> <a href="https://discord.gg/AHEt8BEwzG" target="_blank">https://discord.gg/AHEt8BEwzG</a></li>
</ul>

            <footer class="footline">
            </footer>
          </article>

          <section>
            <h1 class="a11y-only">Subsections of LocalAI</h1>
          <article class="default">
            <header class="headline">
            </header>
<h1 id="install-localai-models">Install LocalAI Models</h1>

<p><a href="#R-image-689f40f0eb91fb5d927fe27a07a8e374" class="lightbox-link"><img src="https://tea-cup.midori-ai.xyz/download/Midori_subsystem_x_localai.png" alt="Midori AI photo" class="figure-image noborder lightbox noshadow" style="height: auto; width: auto;" loading="lazy"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-689f40f0eb91fb5d927fe27a07a8e374"><img src="https://tea-cup.midori-ai.xyz/download/Midori_subsystem_x_localai.png" alt="Midori AI photo" class="lightbox-image noborder lightbox noshadow" loading="lazy"></a></p>
<h2 id="install-a-model-from-the-midori-ai-model-repo">Install a Model from the Midori AI Model Repo</h2>
<h4 id="step-1">Step 1:</h4>
<ul>
<li>Start the Midori AI Subsystem</li>
</ul>
<h4 id="step-2">Step 2:</h4>
<ul>
<li>On the Main Menu, Type <code>5</code> to Enter the Backend Program Menu</li>
</ul>
<h4 id="step-3">Step 3:</h4>
<ul>
<li>On the Backend Program Menu, Type <code>10</code> to Enter the LocalAI Model Installer</li>
</ul>
<h4 id="step-4a">Step 4a:</h4>
<ul>
<li>If you have LocalAI installed in the subsystem, skip this step.</li>
<li>If you do not have LocalAI installed in the subsystem, the program will ask you to enter the LocalAI docker&rsquo;s name. It will look something like <code>localai-api-1</code>, but not always. If you need help, reach out on the <a href="https://discord.gg/xdgCx3VyHU" target="_blank">Midori AI Discord</a> / <a href="mailto:contact-us@midori-ai.xyz" target="_blank">Email</a>.</li>
</ul>
<h4 id="step-4b">Step 4b:</h4>
<ul>
<li>If you have GPU support installed in that image, type <code>yes</code>.</li>
<li>If you do not have GPU support installed in that image, type <code>no</code>.</li>
</ul>
<h4 id="step-5">Step 5:</h4>
<ul>
<li>Type in the size you would like for your LLM and then follow the prompts in the manager!</li>
</ul>
<h4 id="step-6">Step 6:</h4>
<ul>
<li>Sit Back and Let the Model Download from Midori AI&rsquo;s Model Repo</li>
<li>Don&rsquo;t forget to note the name of the model you just installed so you can request it for OpenAI V1 later.</li>
</ul>
<p>Need help on how to do that? Stop by - <a href="/howtos/by_hand/easy-request/index.html">How to send OpenAI request to LocalAI</a></p>
<h2 id="install-a-hugging-face-model-from-the-midori-ai-model-repo">Install a Hugging Face Model from the Midori AI Model Repo</h2>
<h4 id="step-1-1">Step 1:</h4>
<ul>
<li>Start the Midori AI Subsystem</li>
</ul>
<h4 id="step-2-1">Step 2:</h4>
<ul>
<li>On the Main Menu, Type <code>5</code> to Enter the Backend Program Menu</li>
</ul>
<h4 id="step-3-1">Step 3:</h4>
<ul>
<li>On the Backend Program Menu, Type <code>10</code> to Enter the LocalAI Model Installer</li>
</ul>
<h4 id="step-4a-1">Step 4a:</h4>
<ul>
<li>If you have LocalAI installed in the subsystem, skip this step.</li>
<li>If you do not have LocalAI installed in the subsystem, the program will ask you to enter the LocalAI docker&rsquo;s name. It will look something like <code>localai-api-1</code>, but not always. If you need help, reach out on the <a href="https://discord.gg/xdgCx3VyHU" target="_blank">Midori AI Discord</a> / <a href="mailto:contact-us@midori-ai.xyz" target="_blank">Email</a>.</li>
</ul>
<h4 id="step-4b-1">Step 4b:</h4>
<ul>
<li>If you have GPU support installed in that image, type <code>yes</code>.</li>
<li>If you do not have GPU support installed in that image, type <code>no</code>.</li>
</ul>
<h4 id="step-5-1">Step 5:</h4>
<ul>
<li>Type <code>huggingface</code> when asked what size of model you would like.</li>
</ul>
<h4 id="step-6-1">Step 6:</h4>
<ul>
<li>Copy and Paste the Hugging Face Download URL That You Wish to Use</li>
<li>For example: <code>https://huggingface.co/mlabonne/gemma-7b-it-GGUF/resolve/main/gemma-7b-it.Q2_K.gguf?download=true</code>
<a href="#R-image-040a6c68d714463f0352beeb67cacb0c" class="lightbox-link"><img src="https://tea-cup.midori-ai.xyz/download/0a975dc7-ff7f-42a9-a77c-8efdd5bd95e4-chrome_tC2H9nfRdA.png" alt="midori ai photo" class="figure-image noborder lightbox noshadow" style="height: auto; width: auto;" loading="lazy"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-040a6c68d714463f0352beeb67cacb0c"><img src="https://tea-cup.midori-ai.xyz/download/0a975dc7-ff7f-42a9-a77c-8efdd5bd95e4-chrome_tC2H9nfRdA.png" alt="midori ai photo" class="lightbox-image noborder lightbox noshadow" loading="lazy"></a></li>
<li>Or you can use the huggingface naming from their api</li>
<li>For example: <code>mlabonne/gemma-7b-it-GGUF/gemma-7b-it.Q2_K.gguf</code></li>
</ul>
<h4 id="step-7">Step 7:</h4>
<ul>
<li>Sit Back and Let the Model Download from Midori AI&rsquo;s Model Repo</li>
<li>Don&rsquo;t forget to note the name of the model you just installed so you can request it for OpenAI V1 later.</li>
</ul>
<p>Need help on how to do that? Stop by - <a href="/howtos/by_hand/easy-request/index.html">How to send OpenAI request to LocalAI</a></p>

            <footer class="footline">
            </footer>
          </article>

          </section>
        </div>
      </main>
    </div>
    <script src="/js/clipboard.min.js?1722410087" defer></script>
    <script src="/js/perfect-scrollbar.min.js?1722410087" defer></script>
    <script src="/js/theme.js?1722410087" defer></script>
  </body>
</html>
